# -*- coding: utf-8 -*-
"""mask or no mask

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17n8V3nqQl2kuBTRuuAMGzUtIVDeaQJ0p
"""

# Inicializamos Dataset
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt

# Preparar imágenes y etiquetas
TAMANO_IMG = 100

datos_entrenamiento = []

from google.colab import files
uploaded = files.upload()

import zipfile

with zipfile.ZipFile("archive.zip", 'r') as zip_ref:
    zip_ref.extractall("mask")

# Ruta base
base_dir = "mask/data"
TAMANO_IMG = 100

# Carga clase 0 (sin mascara)
without_mask_dir = os.path.join(base_dir, "without_mask")
for archivo in os.listdir(without_mask_dir):
    path = os.path.join(without_mask_dir, archivo)
    img = cv2.imread(path)
    if img is not None:
        img = cv2.resize(img, (TAMANO_IMG, TAMANO_IMG))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = img.reshape(TAMANO_IMG, TAMANO_IMG, 1)
        datos_entrenamiento.append([img, 0]) # clase 0 = sin mascara

# Carga clase 1 (con mascara)
with_mask_dir = os.path.join(base_dir, "with_mask")
for archivo in os.listdir(with_mask_dir):
    path = os.path.join(with_mask_dir, archivo)
    img = cv2.imread(path)
    if img is not None:
        img = cv2.resize(img, (TAMANO_IMG, TAMANO_IMG))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = img.reshape(TAMANO_IMG, TAMANO_IMG, 1)
        datos_entrenamiento.append([img, 1]) # clase 1 = con mascara

print(f"Total de imágenes cargadas: {len(datos_entrenamiento)}")

# Mostrar shape de la primera imagen
print(datos_entrenamiento[0][0].shape)

import matplotlib.pyplot as plt

for i in range(5):  # Mostrar las primeras 5 imágenes
    img, label = datos_entrenamiento[i]
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title(f"Clase: {label} (1 = mask)")
    plt.axis('off')
    plt.show()

import matplotlib.pyplot as plt

# Filtrar solo imágenes con etiqueta 1 (humanos)
imagenes_humanos = [img for img, etiqueta in datos_entrenamiento if etiqueta == 1]

# Ver cuántas imágenes humanas se han cargado
print(f"Total de imágenes de humanos cargadas: {len(imagenes_humanos)}")

# Mostrar las primeras 10 imágenes humanas
plt.figure(figsize=(15, 5))
for i in range(min(10, len(imagenes_humanos))):
    plt.subplot(2, 5, i+1)
    plt.imshow(imagenes_humanos[i].reshape(TAMANO_IMG, TAMANO_IMG), cmap='gray')
    plt.title("Humano")
    plt.axis('off')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Filtrar solo imágenes con etiqueta 1 (humanos)
imagenes_humanos = [img for img, etiqueta in datos_entrenamiento if etiqueta == 0 ]

# Ver cuántas imágenes humanas se han cargado
print(f"Total de imágenes de humanos cargadas: {len(imagenes_humanos)}")

# Mostrar las primeras 10 imágenes humanas
plt.figure(figsize=(15, 5))
for i in range(min(10, len(imagenes_humanos))):
    plt.subplot(2, 5, i+1)
    plt.imshow(imagenes_humanos[i].reshape(TAMANO_IMG, TAMANO_IMG), cmap='gray')
    plt.title("Humano")
    plt.axis('off')
plt.tight_layout()
plt.show()

import os

# Mostrar los archivos dentro de "mask"
for raiz, carpetas, archivos in os.walk("mask"):
    print(f"Ruta: {raiz}, Archivos: {len(archivos)}")
    for archivo in archivos[:5]:  # Muestra los primeros 5
        print(" -", archivo)

print(datos_entrenamiento[0][0][:5, :5, 0])  # Ver primeros 5x5 píxeles

# Mezclar y separar datos
import random
random.shuffle(datos_entrenamiento)

x, y = [], []
for imagen, etiqueta in datos_entrenamiento:
    x.append(imagen)
    y.append(etiqueta)

x = np.array(x).astype('float32') / 255.0
y = np.array(y)

# Visualización de muestras
plt.figure(figsize=(20, 8))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x[i].reshape(TAMANO_IMG, TAMANO_IMG), cmap='gray')

# Importar generador con aumento de datos
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = "mask/data"
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=15,
    zoom_range=[0.7, 1.4],
    horizontal_flip=True,
    vertical_flip=True
)
datagen.fit(x)

# Mostrar ejemplos aumentados
plt.figure(figsize=(20, 8))
for imagen, etiqueta in datagen.flow(x, y, batch_size=10, shuffle=False):
    for i in range(10):
        plt.subplot(2, 5, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.imshow(imagen[i].reshape(TAMANO_IMG, TAMANO_IMG), cmap='gray')
    break

# Arquitectura CNN
from tensorflow.keras import layers, models, Input

input_layer = Input(shape=(TAMANO_IMG, TAMANO_IMG, 1))

x_arq = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)
x_arq = layers.MaxPooling2D(2, 2)(x_arq)
x_arq = layers.Conv2D(64, (3, 3), activation='relu')(x_arq)
x_arq = layers.MaxPooling2D(2, 2)(x_arq)
x_arq = layers.Conv2D(128, (3, 3), activation='relu')(x_arq)
x_arq = layers.MaxPooling2D(2, 2)(x_arq)
x_arq = layers.Flatten()(x_arq)
x_arq = layers.Dense(100, activation='relu')(x_arq)
output_layer = layers.Dense(1, activation='sigmoid')(x_arq)

modeloCNN_AD = models.Model(inputs=input_layer, outputs=output_layer)
modeloCNN_AD.compile(optimizer='adam',
                     loss='binary_crossentropy',
                     metrics=['accuracy'])

# División del dataset
total = len(x)
entrenamiento_size = int(total * 0.85)

x_entrenamiento = x[:entrenamiento_size]
x_validacion = x[entrenamiento_size:]
y_entrenamiento = y[:entrenamiento_size]
y_validacion = y[entrenamiento_size:]

data_gen_entrenamiento = datagen.flow(x_entrenamiento, y_entrenamiento, batch_size=32)

# Entrenamiento
from tensorflow.keras.callbacks import TensorBoard

tensorboardCNN_AD = TensorBoard(log_dir='logs/cnn_AD')

modeloCNN_AD.fit(
    data_gen_entrenamiento,
    epochs=100,
    batch_size=32,
    validation_data=(x_validacion, y_validacion),
    steps_per_epoch=int(np.ceil(len(x_entrenamiento) / float(32))),
    validation_steps=int(np.ceil(len(x_validacion) / float(32))),
    callbacks=[tensorboardCNN_AD]
)

# Commented out IPython magic to ensure Python compatibility.
# TensorBoard
# %load_ext tensorboard
# %tensorboard --logdir logs

# Exportar modelo
modeloCNN_AD.export("modelo_terminado")

# Conversión a TensorFlow.js
!pip install tensorflowjs
!mkdir clas_mask
!tensorflowjs_converter \
  --input_format=tf_saved_model \
  --output_format=tfjs_graph_model \
  modelo_terminado clas_mask